音视频基础知识
===


基本概念
---

- 图像
    图像是人类视觉的基础，是自然景物的客观反映，是人类认识世界和人类本身发展的重要源泉。“图”是物体反射或透射光的分布，“像”是人的视觉系统所接收的图在人脑中所形成的印象或认识。图像是客观对象的一种相似性的、生动性的描述或写真，是人类社会活动中最常用的信息载体，或者说图像是客观对象的一种表示，它包含了被描述对象的有关信息。广义上，图像就是所有具有视觉效果的画面，包括纸介质的、底片或照片上的、电视上的、投影仪或计算机屏幕上的画面。在计算机领域，与图像相关的概念非常多，包括像素、PPI、图像位深度等。

    图像本质上是由很多“带有颜色的点”组成的，而这些点，就是“像素”。像素的英文叫Pixel，缩写为PX。这个单词是由图像(Picture)和元素(Element)这两个单词所组成的。

    像素是图像显示的基本单位，分辨率是指一张图片的宽度和高度的乘积，单位是像素。通常说一张图片的大小，例如1920×1080像素，是指宽度为1920像素，高度为1080像素。它们的乘积是1920×1080=2 073 600，也就是说这张图片是两百万像素的。1920×1080，也被称为这幅图片的分辨率

- 媒体

    是表示，传输，存储信息的载体，常人们见到的文字、声音、图像、图形等都是表示信息的媒体。

- 多媒体

    是声音、动画、文字、图像和录像等各种媒体的组合，以图文并茂，生动活泼的动态形式表现出来，给人以很强的视觉冲击力，留下深刻印象.

- 多媒体技术

    是将文字、声音、图形、静态图像、动态图像与计算集成在一起的技术。它要解决的问题是计算机进一步帮助人类按最自然的和最习惯的方式接受和处理信息。

- 流媒体

    流媒体是指采用流式传输的方式在`Internet`播放的连续时基媒体格式，实际指的是一种新的媒体传送方式，而不是一种新的媒体格式（在网络上传输音/视频等多媒体信息现在主要有下载和流式传输两种方式）流式传输分两种方法：实时流式传输方式(`Realtime Streaming`)和顺序流式传输方式(`Progressive Streaming`)。

- 多媒体文件

    既包括视频又包括音频，甚至还带有脚本的一个集合，也可以叫容器。

- 媒体编码

    是文件当中的视频和音频所采用的压缩算法。也就是说一个`avi`的文件，当中的视频编码有可能是`A`，也可能是`B`，而其音频编码有可能是`1`，也有可能是`2`。

- 转码

    指将一段多媒体包括音频、视频或者其他的内容从一种编码格式转换成为另外一种编码格式。

- 帧

    帧就是一段数据的组合，它是数据传输的基本单位。就是影像动画中最小单位的单幅影像画面，相当于电影胶片上的每一格镜头。一帧就是一副静止的画面，连续的帧就形成动画，如电视图像等。

- 视频

    连续的图象变化每秒超过24帧(`Frame`)画面以上时，根据视觉暂留原理，人眼无法辨别单幅的静态画面，看上去是平滑连续的视觉效果，这样连续的画面叫做视频.

- 音频

    人类能听到的声音都成为音频，但是一般我们所说到的音频时存储在计算机里的声音。

- 比特率(码率)
    码率就是数据传输时单位时间传送的数据位数,一般我们用的单位是`kbps`即千位(bit)每秒，也就是每秒钟传送多少个千位的信息。 通俗一点的理解就是取样率，单位时间内取样率越大，精度就越高，处理出来的文件就越接近原始文件，但是文件体积与取样率是成正比的，所以几乎所有的编码格式重视的都是如何用最低的码率达到最少的失真。但是因为编码算法不一样，所以也不能用码率来统一衡量音质或者画质.小写的b表示bit(位)，大写的B表示byte(字节)，一个字节=8个位，即1B=8b；前面的k表示1024的意思，即1024个位(Kb)或者1024个字节(KB)，表示文件的大小单位，一般使用KB。1KB/s=8Kbps。码率(kbps)=文件大小(KB)*8/时间(秒)。     
- 动态码率(VBR: Variable Bit Rate)
  
    比特率可以随着图像复杂程度的不同而随之变化。图像内容简单的片段采用较小的码率，图像内容复杂的片段采用较大的码率，这样既保证了播放质量，又兼顾了数据量的限制。例如RMVB视频文件，其中的VB就是指VBR，表示采用动态比特率编码方式，达到播放质量与体积兼得的效果。 使用VBR编码时，系统将自动为内容的简单部分分配较少的比特，从而留出足量的比特用于生成高质量的复杂部分。这意味着复杂性恒定的内容（例如新闻播音）不会受益于VBR编码。

    对混合内容使用VBR编码时，在文件大小相同的条件下，VBR编码的输出结果要比CBR编码的输出结果质量好得很多。在某些情况下，与CBR编码文件质量相同的VBR编码文件，其大小可能只有前者的一半。
  
- 静态比特率(CBR: Constant Bit Rate)
    固定比特率，指文件从头到尾都是一种位速率。在流式播放方案中使用CBR编码最为有效。使用CBR编码时，比特率在流的进行过程中基本保持恒定并且接近目标比特率，始终处于由缓冲区大小确定的时间窗内。

    CBR编码的缺点在于编码内容的质量不稳定。因为内容的某些片段要比其他片段更难压缩，所以CBR流的某些部分质量就比其他部分差。此外，CBR编码会导致相邻流的质量不同。通常在较低比特率下，质量的变化会更加明显。
    
  
- 帧率(Frame Rate)
  

帧/秒(`frames per second`)的缩写帧率即每秒显示帧数，帧率表示图形处理器处理场时每秒钟能够更新的次数。高的帧率可以得到更流畅、更逼真的动画。一般来说`30fps`就是可以接受的，但是将性能提升至`60fps`则可以明显提升交互感和逼真感，但是一般来说超过`75fps`一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为监视器不能以这么快的速度更新，这样超过新率的帧率就浪费掉了。
  ![image](https://github.com/CharonChui/Pictures/blob/master/fps.gif?raw=true)

- 关键帧

    相当于二维动画中的原画，指角色或者物体运动或变化中的关键动作所处的那一帧，它包含了图像的所有信息，后来帧仅包含了改变了的信息。如果你没有足够的关键帧，你的影片品质可能比较差，因为所有的帧从别的帧处产生。对于一般的用途，一个比较好的原则是每5秒设一个关键键。但如果时那种实时传输的流文件，那么要考虑传输网络的可靠度，所以要1到2秒增加一个关键帧。

- 刷新率

    刷新率是指屏幕每秒画面被刷新的次数，刷新率分为垂直刷新率和水平刷新率，一般提到的刷新率通常是指垂直刷新率。垂直刷新率表示屏幕上图像每秒重绘多少次，也就是每秒屏幕刷新的次数，以Hz（赫兹）为单位。刷新率越高，图像就越稳定，图像显示就越自然清晰，对眼镜的影响也越小。刷新率月底，图像闪烁和抖动的就越厉害，眼镜疲劳的越快。一般来说，如果能达到80Hz以上的刷新率，就可以完全消除图像闪烁和抖动感。

- 分辨率
    分辨率是一个表示平面图像精细程度的概念，通常它是以横向和纵向点的数量来衡量的，表示成水平点数垂直点数的形式，在计算机显示领域我们也表示成“每英寸像素”（ppi）。
     在一个固定的平面内，分辨率越高，意味着可使用的点数越多，图像越细致。分辨率有多种，在显示器上有表示显示精度的显示分辨率，在打印机上有表示打印精度的打印分辨率，在扫描仪上有表示扫描精度的扫描分辨率。

    下面我们重点介绍一下显示分辨率：

    显示分辨率是显示器在显示图像时的分辨率，分辨率是用点来衡量的，显示器上这个“点”就是指像素（pixel）。显示分辨率的数值是指整个显示器所有可视面积上水平像素和垂直像素的数量。

    例如800×600的分辨率，是指在整个屏幕上水平显示800个像素，垂直显示600个像素。显示分辨率的水平像素和垂直像素的总数总是成一定比例的，一般为4：3、5：4或8：5 。每个显示器都有自己的最高分辨率，并且可以兼容其它较低的显示分辨率，所以一个显示器可以用多种不同的分辨率显示。

    显示分辨率虽然是越高越好，但是还要考虑一个因素，就是人眼能否识别。例如，在14英寸最高分辨率为 1024×768的显示器上800×600是人眼能识别的最高分辨率（我们称为最佳分辨率）。1024× 768 这个分辨率下显示器虽然可以精确的显示图像，但人眼已不能准确的识别屏幕信息了。

    LCD液晶显示器和传统的CRT显示器，分辨率都是重要的参数之一。传统CRT显示器所支持的分辨率较有弹性，而LCD的像素间距已经固定，所以支持的显示模式不像CRT那么多。LCD的最佳分辨率，也叫最大分辨率，在该分辨率下，液晶显示器才能显现最佳影像。

每个像素有RGB三种颜色组成，每色有8bit，取值范围为(0 ~ 255)也就是2的8次方。这种方式表达出来的颜色，也被称为24位色(占用24bit)。
1080P的P是指Progressive scan(逐行扫描)，即垂直方向像素点，也就是高。所以1920*1080叫1080P，不叫1920P。


RGB为3个分量，假如每个分量占8b，取值分别为0～255。那么这3个分量的组合取值为256×256×256=16 777 216种，因此也简称为1600万色。这种颜色范围已经超过了人眼可见的全部色彩，所以又叫真彩色。更高的精度，对于人眼来讲，已经没有意义了，完全识别不出来。RGB这3色，每色有8b，这种方式表达出来的颜色，也被称为24位真彩色。

- PPI
    每英寸的像素数(Pixels Per Inch，PPI)是手机屏幕（或计算机显示器）上每英寸面积到底能放下多少“像素”。这个值越高，图像就越清晰细腻。
    PPI是像素的密度单位，PPI值越高，画面的细节就越丰富，所以数码相机拍出来的图片因品牌或生产时间不同可能有所不同，常见的有72PPI、180PPI和300PPI。DPI(Dots Per Inch)是指输出分辨率，是针对输出设备而言的，一般的激光打印机的输出分辨率为[300DPI，600DPI]，印刷的照排机可达到[1200DPI，2400DPI]，常见的冲印一般为[150DPI，300DPI]。

- DTS

    Decode Time Stamp，主要用于标识读入内存中的比特流在什么时候开始送入解码器中进行解码。

- PTS

    Presentation Time Stamp，主要用于度量解码后的视频帧什么时候被显示出来。

![](https://raw.githubusercontent.com/CharonChui/Pictures/master/gop_dts_pts.jpg)


音视频压缩编码标准
---

为什么要有编码? 
以一个分辨率1920×1280，帧率30的视频为例：
共：1920×1280=2,073,600（Pixels 像素），每个像素点是24bit；
也就是：每幅图片2073600×24=49766400 bit，8 bit（位）=1 byte（字节）；
所以：49766400bit=6220800byte≈6.22MB。

这是一幅1920×1280图片的原始大小，再乘以帧率30。
也就是说：每秒视频的大小是186.6MB，每分钟大约是11GB，一部90分钟的电影，
约是1000GB。。。

编码的终极目的，说白了，就是为了压缩。各种五花八门的视频编码方式，都是为了让视频变得体积更小，有利于存储和传输。


多媒体编辑码方式就是指通过特定的压缩技术，将某个视频格式的文件转换成另一种视频格式文件的方式，现在主要的编码方式有:    

- `MPEG`系列:由国际标准组织机构(`ISO`)下属的运动图象专家组(`MPEG`)开发。视频编码方面主要是`Mpeg1`、`Mpeg2`、`Mpeg4`、`Mpeg4 AVC`。音频编码方面主要是`MPEG Audio Layer 1/2`、`MPEG Audio Layer 3`、`MPEG-2 AAC`、`MPEG-4 AAC`等等:   

    - `MPEG-1`第二部分，主要使用在`VCD`上，有些在线视频也使用这种格式。该编解码器的质量大致上和原有的`VHS`录像带相当。
    - `MPEG-2`第二部分，等同于`H.262`，使用在`DVD`、`SVCD`和大多数数字视频广播系统和有线分布系统中。
    - `MPEG-4`第二部分，可以使用在网络传输、广播和媒体存储上。比起`MPEG-2`第二部分和第一版的`H.263`，它的压缩性能有所提高。
    - `MPEG-4`第十部分，等同于`H.264`，是这两个编码组织合作诞生的标准。


- `H.26X`系列：由国际电传视讯联盟远程通信标准化组织(`ITU-T`)主导，包括`H.261`、`H.262`、`H.263`、`H.264`、`H.265`。
    - `H.261`主要用于老的视频会议和视频电话系统。是第一个使用的数字视频压缩标准。实质上说，之后的所有的标准视频编解码器都是基于它设计的。
    - `H.262`等同于`MPEG-2`第二部分，使用在`DVD`、`SVCD`和大多数数字视频广播系统和有线分布系统中。
    - `H.263`主要用于视频会议、视频电话和网络视频相关产品。在对逐行扫描的视频源进行压缩的方面，`H.263` 比它之前的视频编码标准在性能上有了较大的提升。尤其是在低码率端，它可以在保证一定质量的前提下大大的节约码率。
    - `H.264`等同于`MPEG-4`第十部分，也被称为高级视频编码(`Advanced Video Coding`，简称 `AVC`)，是一种视频压缩标准，一种被广泛使用的高精度视频的录制、压缩和发布格式。该标准引入了一系列新的能够大大提高压缩性能的技术，并能够同时在高码率端和低码率端大大超越以前的诸标准。
    - `H.265`被称为高效率视频编码(`High Efficiency Video Coding`，简称`HEVC`)是一种视频压缩标准，是`H.264`的继任者。`HEVC` 被认为不仅提升图像质量，同时也能达到`H.264`两倍的压缩率（等同于同样画面质量下比特率减少了50%），可支持`4K` 分辨率甚至到超高画质电视，最高分辨率可达到`8192×4320`(`8K`分辨率)，这是目前发展的趋势。


- 微软`Windows Media`系列:视频编码有`Mpeg-4 v1/v2/v3`、`Windows Media Video 7/8/9/10`；音频编码有`Windows Media audeo v1/v2/7/8/9`。    
- `Real Media`系列:视频编码有`RealVideo G2`、`RealVideo 8/9/10`；音频编码有`RealAudio cook/sipro`、`RealAudio AAC/AACPlus`等。  
- `QuickTime`系列:视频编码有`Sorenson Video 3`、`Apple MPEG-4`、`Apple H.264`；音频编码有`QDesign Music 2`、`Apple MPEG-4 AAC`。   
- 其它如：`Ogg`、`On2-vpx`、`flash vidio`，以及`M-JPEG`视频压缩方式。    


简单的总结一下上面的两条就是，视频编码标准有两大系统:  

- MPEG:MPEG标准由MPEG制定，MPEG-1 | MPEG-2 | MPEG-3 | MPEG-4 | MPEG-7 | MPEG-21
- ITU-T:ITU-T标准由VCEG制定，H.261 | H.262 | H.263 | H.263v2 | H.264



#### 音频编解码方式

视频中除了画面通常还有声音，所以这就涉及到音频编解码。在视频中经常使用的音频编码方式有: 

- `AAC`:(`Advanced Audio Coding`)，是由`Fraunhofer IIS`、`杜比实验室`、`AT&T`、`Sony`等公司共同开发，在1997年推出的基于`MPEG-2` 的音频编码技术。2000年，`MPEG-4`标准出现后，`AAC`重新集成了其特性，加入了`SBR`技术和`PS`技术，为了区别于传统的`MPEG-2 AAC`又称为`MPEG-4 AAC`。
- `MP3`:(`MPEG-1 or MPEG-2 Audio Layer III`)，是当曾经非常流行的一种数字音频编码和有损压缩格式，它被设计来大幅降低音频数据量。它是在1991 年，由位于德国埃尔朗根的研究组织`Fraunhofer-Gesellschaft`的一组工程师发明和标准化的。`MP3`的普及曾对音乐产业造成极大的冲击与影响。
- `WMA`:(`Windows Media Audio`)由微软公司开发的一种数字音频压缩格式，本身包括有损和无损压缩格式。


MPEG-1 or MPEG-2 Audio Layer III是一种音频压缩技术，其全称是动态影像专家压缩标准音频层面3（Moving Picture Experts Group Audio Layer III），简称为MP3，是目前最流行的音频编码格式。
    MP3文件是由帧（frame）构成的，帧是MP3文件最小的组成单位。MPEG音频文件是MPEG1标准中的声音部分，也叫MPEG音频层，它根据压缩质量和编码复杂程度划分为三层，即 Layer-1、Layer2、Layer3，且分别对应MP1、MP2、MP3这三种声音文件，并根据不同的用途，使用不同层次的编码。MPEG音频编码的层次越高，编码器越复杂，压缩率也越高，MP1和MP2的压缩率分别为4:1和6:1-8:1，而MP3的压缩率则高达10:1-12:1，也就是说，一分钟CD音质的音乐，未经压缩需要10MB的存储空间，而经过MP3压缩编码后只有1MB左右。不过MP3对音频信号采用的是有损压缩方式，为了降低声音失真度，MP3采取了“感官编码技术”，即编码时先对音频文件进行频谱分析，然后用过滤器滤掉噪音电平，接着通过量化的方式将剩下的每一位打散排列，最后形成具有较高压缩比的MP3文件，并使压缩后的文件在回放时能够达到比较接近原音源的声音效果。根据MPEG规范的说法，MPEG-4中的AAC（Advanced audio coding）将是MP3格式的下一代。

音频编码方案之间音质比较（AAC，MP3，WMA等）结果： 

AAC+ > MP3PRO > AAC> RealAudio > WMA > MP3
目前最常见的音频格式有 Mp3、AC-3、ACC，MP3最广泛的支持最多，AC-3是杜比公司的技术，ACC是MPEG-4中的音频标准，ACC是目前比较先进和具有优势的技术。对应入门，知道有这几种最常见的音频格式足以。


#### PCM介绍

PCM是英文Pulse-code modulation的缩写，中文译名是脉冲编码调制。我们知道在现实生活中，人耳听到的声音是模拟信号，PCM就是要把声音从模拟转换成数字信号的一种技术，它的原理简单地说就是利用一个固定的频率对模拟信号进行采样，采样后的信号在波形上看就像一串连续的幅值不一的脉冲，把这些脉冲的幅值按一定的精度进行量化，这些量化后的数值被连续地输出、传输、处理或记录到存储介质中，所有这些组成了数字音频的产生过程。


PCM的采集步骤分为： 
模拟信号 -> 采样 -> 量化 -> 编码  -> 数字信号
---




视频格式(封装格式/容器)
---

把编码后的音视频数据以一定格式封装到一个容器。

目前我们经常见的视频格式无非就是两大类： 

1. 影像格式（Video）
2. 流媒体格式（Stream Video）

在影像格式中还可以根据出处划分为三大种:   

1. `AVI`格式      
    `AVI`英文全称为`Audio Video Interleaved`，即音频视频交错格式，是微软公司于1992年11月推出、作为其`Windows`视频软件一部分的一种多媒体容器格式。
    `AVI`文件将音频（语音）和视频（影像）数据包含在一个文件容器中，允许音视频同步回放。类似`DVD`视频格式，`AVI`文件支持多个音视频流。`AVI`信息主要应用在多媒体光盘上，用来保存电视、电影等各种影像信息。    
    其中数据块包含实际数据流，即图像和声音序列数据。这是文件的主体，也是决定文件容量的主要部分。视频文件的大小等于该文件的数据率乘以该视频播放的时间长度，
    索引块包括数据块列表和它们在文件中的位置，以提供文件内数据随机存取能力。文件头包括文件的通用信息，定义数据格式，所用的压缩算法等参数。      
    `AVI`没有`MPEG`这么复杂，从`Windows 3.1`时代，它就已经面世了。它最直接的优点就是兼容好、调用方便而且图象质量好，因此也常常与`DVD`相并称。
    但它的缺点也是十分明显的：体积大。也是因为这一点，我们才看到了`MPEG-1`和`MPEG-4`的诞生。2小时影像的`AVI`文件的体积与`MPEG-2`相差无几，
    不过这只是针对标准分辨率而言的：根据不同的应用要求，`AVI`的分辨率可以随意调。窗口越大，文件的数据量也就越大。降低分辨率可以大幅减低它的体积，
    但图象质量就必然受损。与`MPEG-2`格式文件体积差不多的情况下，`AVI`格式的视频质量相对而言要差不少，但制作起来对电脑的配置要求不高，经常有人先录制好了`AVI`格式的视频，再转换为其他格式。
2. `MOV`格式
    `MOV`即`QuickTime`影片格式，它是`Apple`公司开发的一种音频、视频文件格式，用于存储常用数字媒体类型。当选择`QuickTime（*.mov）`作为“保存类型”时，动画将保存为`·mov`文件。`QuickTime`用于保存音频和视频信息，包括`Apple Mac OS，MicrosoftWindows95/98/NT/2003/XP/VISTA`，甚至`WINDOWS7`在内的所有主流电脑平台支持。`QuickTime`因具有跨平台、存储空间要求小等技术特点，而采用了有损压缩方式的`MOV`格式文件，画面效果较AVI格式要稍微好一些。到目前为止，它共有4个版本，其中以`4.0`版本的压缩率最好。这种编码支持16位图像深度的帧内压缩和帧间压缩，帧率每秒10帧以上。这种格式有些非编软件也可以对它实行处理，其中包括`ADOBE`公司的专业级多媒体视频处理软件`AFTEREFFECTS和PREMIERE`。

3. `MPEG/MPG/DAT`:
    这是由国际标准化组织`ISO(International Standards Organization)`与`IEC(International Electronic Committee)`联合开发的一种编码视频格式。`MPEG`是运动图像压缩算法的国际标准，现已被几乎所有的计算机平台共同支持。MPEG也是`Motion Picture Experts Group`的缩写。这类格式包括了`MPEG-1, MPEG-2`和`MPEG-4`在内的多种视频格式。`MPEG-1`相信是大家接触得最多的了，因为目前其正在被广泛地应用在`VCD`的制作和一些视频片段下载的网络应用上面，大部分的`VCD`都是用 `MPEG1`格式压缩的( 刻录软件自动将`MPEG1`转为`.DAT`格式)，使用`MPEG-1`的压缩算法，可以把一部120分钟长的电影压缩到1.2GB左右大小。`MPEG-2`则是应用在`DVD` 的制作，同时在一些`HDTV`（高清晰电视广播）和一些高要求视频编辑、处理上面也有相当多的应用。使用`MPEG-2`的压缩算法压缩一部120分钟长的电影可以压缩到5-8GB的大小（`MPEG2`的图像质量`MPEG-1`与其无法比拟的）。

在流媒体格式中同样还可以划分为三种:      

1. `RM`格式
    `Real Networks`公司所制定的音频/视频压缩规范`Real Media`中的一种，`Real Player`能做的就是利用`Internet`资源对这些符合`Real Media`技术规范的音频/视频进行实况转播。在`Real Media`规范中主要包括三类文件：`RealAudio`、`Real Video`和`Real Flash`（`Real Networks`公司与`Macromedia`公司合作推出的新一代高压缩比动画格式）。`REAL VIDEO`（RA、RAM）格式由一开始就是定位就是在视频流应用方面的，也可以说是视频流技术的始创者。它可以在用56K`MODEM`拨号上网的条件实现不间断的视频播放，从`RealVideo`的定位来看，就是牺牲画面质量来换取可连续观看性。其实`RealVideo`也可以实现不错的画面质量，由于`RealVideo`可以拥有非常高的压缩效率，很多人把`VCD`编码成`RealVideo`格式的，这样一来，一张光盘上可以存放好几部电影。`REAL VIDEO`存在颜色还原不准确的问题，`RealVideo`就不太适合专业的场合，但`RealVideo`出色的压缩效率和支持流式播放的特征，使得`RealVideo`在网络和娱乐场合占有不错的市场份额。
2. `MOV/QT`格式
    `MOV`也可以作为一种流文件格式。`QuickTime`能够通过`Internet`提供实时的数字化信息流、工作流与文件回放功能，为了适应这一网络多媒体应用，`QuickTime`为多种流行的浏览器软件提供了相应的`QuickTime Viewer`插件，能够在浏览器中实现多媒体数据的实时回放。
3. `ASF`格式
    `ASF`(`Advanced Streaming format`高级流格式)。`ASF`是`MICROSOFT`为了和现在的`Real player`竞争而发展出来的一种可以直接在网上观看视频节目的文件压缩格式。`ASF`使用了`MPEG4`的压缩算法，压缩率和图像的质量都很不错。因为`ASF`是以一个可以在网上即时观赏的视频“流”格式存在的，所以它的图像质量比`VCD`差一点点并不出奇，但比同是视频“流”格式的`RAM`格式要好。 `ASF`支持任意的压缩/解压缩编码方式，并可以使用任何一种底层网络传输协议，具有很大的灵活性。`ASF`流文件的数据速率可以在`28.8Kbps`到`3Mbps`之间变化。用户可以根据自己应用环境和网络条件选择一个合适的速率，实现`VOD`点播和直播。

4. `FLV`格式`FLV`是`FLASH VIDEO`的简称，一种流媒体封装格式，`FLV`流媒体格式是随着`Flash MX`的推出发展而来的视频格式。由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能，它的出现有效地解决了视频文件导入`Flash`后，使导出的`SWF`文件体积庞大，不能在网络上很好的使用等问题。因此`FLV`格式成为了当今主流视频格式


叫做容器很好理解，mp4就是一个容器，里面有moov文件表示文件的信息等，还有音频、画面等信息，他们统一到
一起，放到一个容器里面，就组成了视频。如果觉得难以理解，可以想象成一瓶番茄酱。最外层的瓶子好比这个容器封装（Container），瓶子上注明的原材料和加工厂地等信息好比元信息（Metadata），瓶盖打开（解封装）后，番茄酱本身好比经过压缩处理过后的编码内容，番茄和调料加工成番茄酱的过程就好比编码（Codec），而原材料番茄和调料则好比最原本的内容元素（Content）。


一些音视频的参数含义
---

 数码音频系统是通过将声波波形转换成一连串的二进制数据来再现原始声音的，实现这个步骤使用的设备是模/数转换器（A/D），它以每秒上万次的速率对声波进行采样，每一次采样都记录下了原始模拟声波在某一时刻的状态，称之为样本。

将一串的样本连接起来，就可以描述一段声波了，把每一秒钟所采样的数目称为采样频率或采率，单位为HZ（赫兹）。采样频率越高所能描述的声波频率就越高。采样率决定声音频率的范围（相当于音调），可以用数字波形表示。要正确理解音频采样可以分为采样的位数和采样的频率。

采样的位数：采样位数可以理解为采集卡处理声音的解析度。这个数值越大，解析度就越高，录制和回放的声音就越真实。我们首先要知道：电脑中的声音文件是用数字0和1来表示的。所以在电脑上录音的本质就是把模拟声音信号转换成数字信号。

反之，在播放时则是把数字信号还原成模拟声音信号输出。采集卡的位是指采集卡在采集和播放声音文件时所使用数字声音信号的二进制位数。采集卡的位客观地反映了数字声音信号对输入声音信号描述的准确程度。

8位代表2的8次方—256，16位则代表2的16次方—64K。比较一下，一段相同的音乐信息，16位声卡能把它分为64K个精度单位进行处理，而8位声卡只能处理256个精度单位，造成了较大的信号损失，最终的采样效果自然是无法相提并论的。

#### 采样率

音频的采样率要大于原声波频率的2倍，人耳能听到的最高频率为20kHz，所以为了满人耳的听觉要求，采样率至少为40kHz以上，通常为44.1kHz。 
44.1kHz就是代表1秒会采样44100次。
采样频率：是指录音设备在一秒钟内对声音信号的采样次数，采样频率越高声音的还原就越真实越自然。在当今的主流采集卡上，采样频率一般共分为22.05KHz、44.1KHz、48KHz三个等级，22.05KHz只能达到FM广播的声音品质，44.1KHz则是理论上的CD音质界限，48KHz则更加精确一些。对于高于48KHz的采样频率人耳已无法辨别出来了，所以在电脑上没有多少使用价值。



***声道***：目前人们所使用的各种声场技术规范非常多，但最常见的几乎都来自三家公司，他们是`Dolby`（杜比）、`HTX`和`DTS`。

声卡所支持的声道数是衡量声卡档次的重要指标之一，从单声道到最新的环绕立体声，下面一一详细介绍：

- 单声道：单声道是比较原始的声音复制形式，早期的声卡采用的比较普遍。当通过两个扬声器回放单声道信息的时候，我们可以明显感觉到声音是从两个音箱中间传递到我们耳朵里的。
这种缺乏位置感的录制方式用现在的眼光看自然是很落后的，但在声卡刚刚起步时，已经是非常先进的技术了。
- 立体声：单声道缺乏对声音的位置定位，而立体声技术则彻底改变了这一状况。声音在录制过程中被分配到两个独立的声道，从而达到了很好的声音定位效果。
这种技术在音乐欣赏中显得尤为有用，听众可以清晰地分辨出各种乐器来自的方向，从而使音乐更富想象力，更加接近于临场感受。立体声技术广泛运用于自`Sound Blaster Pro`以后的大量声卡，成为了影响深远的一个音频标准。时至今日，立体声依然是许多产品遵循的技术标准。
- 准立体声：准立体声声卡的基本概念就是：在录制声音的时候采用单声道，而放音有时是立体声，有时是单声道。采用这种技术的声卡也曾在市面上流行过一段时间，但现在已经销声匿迹了。
- 四声道环绕：人们的欲望是无止境的，立体声虽然满足了人们对左右声道位置感体验的要求，但是随着技术的进一步发展，大家逐渐发现双声道已经越来越不能满足我们的需求。
由于`PCI`声卡的出现带来了许多新的技术，其中发展最为神速的当数三维音效。三维音效的主旨是为人们带来一个虚拟的声音环境，通过特殊的HRTF技术营造一个趋于真实的声场，
从而获得更好的游戏听觉效果和声场定位。而要达到好的效果，仅仅依靠两个音箱是远远不够的，所以立体声技术在三维音效面前就显得捉襟见肘了，但四声道环绕音频技术则很好的解决了这一问题。
四声道环绕规定了4个发音点：前左、前右，后左、后右，听众则被包围在这中间。同时还建议增加一个低音音箱，以加强对低频信号的回放处理(这也就是如今4.1声道音箱系统广泛流行的原因)。
就整体效果而言，四声道系统可以为听众带来来自多个不同方向的声音环绕，可以获得身临各种不同环境的听觉感受，给用户以全新的体验。如今四声道技术已经广泛融入于各类中高档声卡的设计中，
成为未来发展的主流趋势。
- 5.1声道:5.1声道已广泛运用于各类传统影院和家庭影院中，一些比较知名的声音录制压缩格式，譬如杜比`AC-3`（`Dolby Digital`）、`DTS`等都是以5.1声音系统为技术蓝本的。其实5.1声音系统来源于4.1环绕，不同之处在于它增加了一个中置单元。这个中置单元负责传送低于`80Hz`的声音信号，在欣赏影片时有利于加强人声，把对话集中在整个声场的中部，以增加整体效果。相信每一个真正体验过`DolbyAC-3`音效的朋友都会为5.1声道所折服。千万不要以为5.1已经是环绕立体声的顶峰了，更强大的7.1系统已经出现了。
它在5.1的基础上又增加了中左和中右两个发音点，以求达到更加完美的境界。由于成本比较高，没有广泛普及。

##### 音频的码率
码率是指一个数据流中每秒钟能通过的信息量，单位是bps(bit per second)。 
码率 = 采样率 * 采样位数 * 声道数。 

YUV
---

YUV(也成YCbCr)是电视系统所采用的一种颜色编码方法，他是一种亮度与色度分离的色彩格式。
- 其中Y表示明亮度(Luminance或Luma)也就是灰阶值，它是基础信号。
- U表示蓝色通道与亮度的差值
- V表示红色通道与亮度的差值(为什么只有蓝色红色，没有绿色，这是因为红蓝绿加起来为1，所以1减去他俩就是绿)
UV的作用是描述影像色彩及饱和度，它们用于指定像素的颜色。
U和V不是基础信号，他俩都是被正交调制的。早期的电视都是黑白的，即只有亮度值(Y)，有了彩色电视之后，加入了UV两种色度，形成现在的YUV。
人眼对亮度敏感，对色度不敏感，因此减少部分UV的数据量，人眼也无法感知出来，这样就可以通过压缩UV的分辨率，在不影响观感的前提下，减少视频的体积。

YUV和RGB视频信号相比，最大的优点在于只需要占用极少的带宽，YUV只需要占用RGB一般的带宽。

YUV 色彩编码模型，其设计初衷为了解决彩色电视机与黑白电视的兼容问题，利用了人类眼睛的生理特性（对亮度敏感，对色度不敏感），允许降低色度的带宽，降低了传输带宽。

在计算机系统中应用尤为广泛，利用 YUV 色彩编码模型可以降低图片数据的内存占用，YUV只需要占用RGB一般的带宽，从而提高数据处理效率。

另外，YUV 编码模型的图像数据一般不能直接用于显示，还需要将其转换为 RGB（RGBA） 编码模型，才能够正常显示图像。



YUV码流的存储格式其实与其采样的方式密切相关，主流的采样方式有四种，
- YUV 4:4:4
YUV三个信道的抽样率相同，因此在生成的图像里，每个象素的三个分量信息完整（每个分量通常8比特），经过8比特量化之后，未经压缩的每个像素占用3个字节。

　　下面的四个像素为: [Y0 U0 V0] [Y1 U1 V1] [Y2 U2 V2] [Y3 U3 V3]

　　存放的码流为: Y0 U0 V0 Y1 U1 V1 Y2 U2 V2 Y3 U3 V3

- YUV 4:2:2 
每个色差信道的抽样率是亮度信道的一半，所以水平方向的色度抽样率只是4:4:4的一半。对非压缩的8比特量化的图像来说，每个由两个水平方向相邻的像素组成的宏像素需要占用4字节内存。

　　下面的四个像素为：[Y0 U0 V0] [Y1 U1 V1] [Y2 U2 V2] [Y3 U3 V3]

　　存放的码流为：Y0 U0 Y1 V1 Y2 U2 Y3 V3

　　映射出像素点为：[Y0 U0 V1] [Y1 U0 V1] [Y2 U2 V3] [Y3 U2 V3]
- YUV 4:2:0 
4:2:0并不意味着只有Y，Cb而没有Cr分量。它指得是对每行扫描线来说，只有一种色度分量以2:1的抽样率存储。相邻的扫描行存储不同的色度分量，也就是说，如果一行是4:2:0的话，下一行就是4:0:2，再下一行是4:2:0...以此类推。对每个色度分量来说，水平方向和竖直方向的抽样率都是2:1，所以可以说色度的抽样率是4:1。对非压缩的8比特量化的视频来说，每个由2x2个2行2列相邻的像素组成的宏像素需要占用6字节内存。

　　下面八个像素为：[Y0 U0 V0] [Y1 U1 V1] [Y2 U2 V2] [Y3 U3 V3]

　　[Y5 U5 V5] [Y6 U6 V6] [Y7U7 V7] [Y8 U8 V8]

　　存放的码流为：Y0 U0 Y1 Y2 U2 Y3

　　Y5 V5 Y6 Y7 V7 Y8

　　映射出的像素点为：[Y0 U0 V5] [Y1 U0 V5] [Y2 U2 V7] [Y3 U2 V7]

　　[Y5 U0 V5] [Y6 U0 V5] [Y7U2 V7] [Y8 U2 V7]
- YUV 4:1:1 
4:1:1的色度抽样，是在水平方向上对色度进行4:1抽样。对于低端用户和消费类产品这仍然是可以接受的。对非压缩的8比特量化的视频来说，每个由4个水平方向相邻的像素组成的宏像素需要占用6字节内存。

　　下面的四个像素为: [Y0 U0 V0] [Y1 U1 V1] [Y2 U2 V2] [Y3 U3 V3]

　　存放的码流为: Y0 U0 Y1 Y2 V2 Y3

　　映射出像素点为：[Y0 U0 V2] [Y1 U0 V2] [Y2 U0 V2] [Y3 U0 V2]


PAR DAR SAR
---

最近开发中遇到了一个问题，就是平时我们都是按照视频的宽高来显示缩放的，也就是分辨率，但是最近确发现了有一个视频会发生变形的情况，而在VLC上面确实正常的，后来追查发现是因为这个视频的PAR并不是1:1，而为什么会出现这种情况呢？ 这事因为视频的制式按照设备可以分为计算机制式和电视制式。而电视制式又可以分为PAL和NTSC。电视制式的PAR通常不为1:1，而计算机制式的PAR为1:1。


- PAR(Pixel Aspect Ratio):像素横纵比。表示每个像素的宽度与长度的比值，大多数情况为1:1，就是一个正方形像素，否则为长方形像素。
- DAR(Display Aspect Ratio):显示横纵比。即最终播放出来的画面的宽和高的比，正规的播放器需要按照DAR来播放视频。
- SAR(Sample Aspect Ratio):采样横纵比。表示横向的像素点数和纵向的像素点数的比值。这也就是我们说的分辨率。
- DAR = PAR x SAR



### 视频播放原理

播放一个本地视频文件，需要经过解封装，解码音视频，音视频同步等步骤。

![image](https://github.com/CharonChui/Pictures/blob/master/video_player_decode.png?raw=true)



- 解封装: 就是将输入的封装格式的数据，分离成音频压缩编码数据和视频压缩编码数据。例如，FLV格式的数据，经过解封装操作后，输出H264编码的视频码流和AAC编码的音频码流。

- 解码: 将视频/音频压缩编码数据，解码成本非压缩的视频/音频原始数据。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420p，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。
- 音视频同步: 根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将音视频数据送至系统的显卡和声卡播放出来。



### 流媒体

上面播放器的是本地视频文件，如果播放的是网络上的视频，步骤则为: 解协议、解封装、解码音视频、音视频同步，多了一个接协议的步骤。

- 解协议: 将流媒体协议的数据，解析为标准的相应的封装格式数据。

  音视频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP、RTMP等等，这些协议在传输音视频数据的同时也会传输一些信令数据。这些信令数据包括对播放的控制(播放、暂停、停止)或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留音视频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。

[常见流媒体协议](https://github.com/CharonChui/AndroidNote/blob/master/VideoDevelopment/%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE/%E6%B5%81%E5%AA%92%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md)

##### 硬件加速


中央处理器(Central Processing Unit，CPU)，包括算术逻辑部件(Arithmetic Logic Unit，ALU)和高速缓冲存储器(Cache)及实现它们之间联系的数据(Data)、控制及状态的总线(Bus)。GPU即图形处理器(Graphics Processing Unit)，专为执行复杂的数学和几何计算而设计的，拥有二维或三维图形加速功能。GPU相比于CPU具有更强大的二维、三维图形计算能力，可以让CPU从图形处理的任务中解放出来，执行其他更多的系统任务，这样可以大大提高计算机的整体性能。硬件加速(Hardware Acceleration)就是利用硬件模块来替代软件算法以充分利用硬件所固有的快速特性，硬件加速通常比软件算法的效率要高。例如将与二维、三维图形计算相关的工作交给GPU处理，从而释放CPU的压力，是属于硬件加速的一种。
































相关知识: 

- [封装格式](https://en.wikipedia.org/wiki/Comparison_of_video_container_formats)
- [视频编码方式](https://en.wikipedia.org/wiki/Comparison_of_video_codecs)
- [音频编码方式](https://en.wikipedia.org/wiki/Comparison_of_audio_coding_formats)

---

- 邮箱 ：charon.chui@gmail.com  
- Good Luck! 
